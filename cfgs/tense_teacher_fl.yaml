session: {
  _comment_: fl_6labels,
  save_path: ./logs,
  project_name : Face_Forensic_teacher,
}

# Support sklearn metrics or custom metrics
train: {
  num_epochs: 40,
  metrics: ["accuracy_score", "f1_score"],
}

# if you want to auto split please set
data : {
  data.class: data_loader.Classify.ClassificationDataset,
  validation_ratio: 0,
  data_csv_name: ./data/csv6labels/data_train.csv,
  validation_csv_name : ./data/csv6labels/data_val.csv,
  test_csv_name: ./data/csv6labels_partial/data_test.csv,
  label_dict: ['original', 'Deepfakes', 'Face2Face', 'FaceSwap', 'FaceShifter', 'NeuralTextures'], # sort by class_id
  batch_size: 64,
}

# model_teacher: {
#   model.class: models.efficientnet_transfer.efficientnet.Efficientnet_transfer,
#   model_name: efficientnet_b5,
#   pretrained: true,
#   num_classes: 6,
# }

model_teacher: {
  model.class: models.resnet_transfer.resnet.Resnet_transfer,
  model_name: resnet50,
  pretrained: true,
  num_classes: 6,
}

model_robust: {
  model.class: models.resnet_transfer.resnet.Resnet_transfer,
  model_name: resnet50,
  pretrained: true,
  num_classes: 6,
}

loss: {
  name: FocalLoss,
  alpha: null,
  gamma: 2,
}

adversarial: {
  perturb_steps: 10,
  step_size: 0.007,
  epsilon: 0.031,
  norm: np.inf,
}

# configure arguments of torch.optim.Optimizer
# You can add other arguments for the Optimizer
# (ex. "name": SGD)
optimizer: {
  name: SGD,
  lr: 1e-2,
  momentum: 0.9,
  weight_decay: 2e-4,
}

# configure arguments of torch.optim.lr_scheduler 
# feel free to add other arguments for the sheduler
# Do not modify this key (eg. "name": CosineAnnealingLR)
scheduler: {
  name: ReduceLROnPlateau,
  min_lr: 1e-6,
  mode: min,
  patience: 10,
  factor: 0.1,
}
