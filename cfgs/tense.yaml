session: {
  _comment_: exp1,
  save_path: ./logs,
  project_name : Face_Forensic_robust,
}

# Support sklearn metrics or custom metrics
train: {
  num_epochs: 100,
  metrics: ["accuracy_score", "f1_score"],
}

# if you want to auto split please set
data : {
  data.class: data_loader.Classify.ClassificationDataset,
  validation_ratio: 0,
  data_csv_name: ./data/csv6labels_partial/data_train.csv,
  validation_csv_name : ./data/csv6labels_partial/data_val.csv,
  test_csv_name: ./data/csv6labels_partial/data_test.csv,
  label_dict: ['original', 'Deepfakes', 'Face2Face', 'FaceSwap', 'FaceShifter', 'NeuralTextures'], # sort by class_id
  batch_size: 12,
}

model_teacher: {
  model.class: models.efficientnet_transfer.efficientnetv2.EfficientnetV2_transfer,
  model_name: tf_efficientnetv2_m,
  pretrained: false,
  num_classes: 6,
}

model_robust: {
  model.class: models.denoise_Resnet.denoiseResnet.Denoise_Resnet,
  model_name: resnet50,
  num_classes: 6,
}


loss: {
  name: LBGATLoss,
  weight: null,
  beta: 1,
}

adversarial: {
  perturb_steps: 10,
  step_size: 0.005,
  epsilon: 0.021,
  # norm: np.inf,
  norm: 2,
}

# configure arguments of torch.optim.Optimizer
# You can add other arguments for the Optimizer
# (ex. "name": SGD)
optimizer: {
  name: SGD,
  lr: 1e-2,
  momentum: 0.9,
  weight_decay: 2e-4,
}

# configure arguments of torch.optim.lr_scheduler 
# feel free to add other arguments for the sheduler
# Do not modify this key (eg. "name": CosineAnnealingLR)
scheduler: {
  name: ReduceLROnPlateau,
  min_lr: 1e-6,
  mode: min,
  patience: 10,
  factor: 0.1,
}
